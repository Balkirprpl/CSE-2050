{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "982870b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dateparser\n",
    "\n",
    "def homework1 ():\n",
    "    file = open(\"Apache_2k.log\")\n",
    "    pattern = \"\"\n",
    "    count = 0\n",
    "    print(\"Date                       Client IP\")\n",
    "    for row in file:\n",
    "        \n",
    "        ips = re.findall(r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\", row)\n",
    "        if ips:\n",
    "            row = row.split(\"]\")\n",
    "            count += 1\n",
    "            row = row[0][1:len(row[0])]\n",
    "            date = dateparser.parse(row).strftime(\"%m/%d/%Y %I:%M:%S %p\")\n",
    "            print(f\"{date}     {ips[0]}\")\n",
    "    print(\"%s %d\" % (\"Total amount of forbidden requests:\", count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cfcf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                       Client IP\n",
      "12/04/2005 05:15:09 AM     222.166.160.184\n",
      "12/04/2005 07:45:45 AM     63.13.186.196\n",
      "12/04/2005 08:54:17 AM     147.31.138.75\n",
      "12/04/2005 09:35:12 AM     207.203.80.15\n",
      "12/04/2005 10:53:30 AM     218.76.139.20\n",
      "12/04/2005 11:11:07 AM     24.147.151.74\n",
      "12/04/2005 11:33:18 AM     211.141.93.88\n",
      "12/04/2005 11:42:43 AM     216.127.124.16\n",
      "12/04/2005 12:33:13 PM     208.51.151.210\n",
      "12/04/2005 01:32:32 PM     65.68.235.27\n",
      "12/04/2005 02:29:00 PM     4.245.93.87\n",
      "12/04/2005 03:18:36 PM     67.154.58.130\n",
      "12/04/2005 03:59:01 PM     24.83.37.136\n",
      "12/04/2005 04:24:05 PM     58.225.62.140\n",
      "12/04/2005 05:34:57 PM     61.138.216.82\n",
      "12/04/2005 05:53:43 PM     218.39.132.175\n",
      "12/04/2005 06:24:22 PM     125.30.38.52\n",
      "12/04/2005 07:36:05 PM     61.37.222.240\n",
      "12/05/2005 01:04:31 AM     218.62.18.218\n",
      "12/05/2005 01:30:32 AM     211.62.201.48\n",
      "12/05/2005 03:23:24 AM     218.207.61.7\n",
      "12/05/2005 03:44:50 AM     168.20.198.21\n",
      "12/05/2005 06:36:59 AM     221.232.178.24\n",
      "12/05/2005 09:09:48 AM     207.12.15.211\n",
      "12/05/2005 10:26:39 AM     141.153.150.164\n",
      "12/05/2005 10:28:44 AM     198.232.168.9\n",
      "12/05/2005 10:48:48 AM     67.166.248.235\n",
      "12/05/2005 02:11:43 PM     141.154.18.244\n",
      "12/05/2005 04:45:04 PM     216.216.185.130\n",
      "12/05/2005 05:31:39 PM     218.75.106.250\n",
      "12/05/2005 07:00:56 PM     68.228.3.15\n",
      "12/05/2005 07:14:09 PM     61.220.139.68\n",
      "Total amount of forbidden requests: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaog\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateparser\\date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    }
   ],
   "source": [
    "homework1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dec346f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def homework2():\n",
    "    class Country:\n",
    "        def __init__(self, name, count):\n",
    "            self.name = name\n",
    "            self.count = count\n",
    "    file = open(\"IMDb_movies.csv\", encoding='utf8')\n",
    "    file = csv.reader(file)\n",
    "    countries_all = []\n",
    "    countries_once = []\n",
    "    countries_end = []\n",
    "    for row in file:\n",
    "        if len(row[7].split(\",\")) >= 2:\n",
    "            for country in row[7].split(\", \"):\n",
    "                countries_all.append(country)\n",
    "                if country not in countries_once:\n",
    "                    countries_once.append(country)\n",
    "        else:\n",
    "            countries_all.append(row[7])\n",
    "            if row[7] not in countries_once:\n",
    "                countries_once.append(row[7])\n",
    "    for country in countries_once:\n",
    "        amount = countries_all.count(country)\n",
    "        countries_end.append(Country(country, amount))\n",
    "    countries_end = sorted(countries_end, key=lambda x:int(x.count), reverse = True)\n",
    "    for i in range(10):\n",
    "        name = countries_end[i].name\n",
    "        count = countries_end[i].count\n",
    "        number_bars = int(count/1000)\n",
    "        spaces = \"\\u2588\"*number_bars\n",
    "        print(f\"%-10s \\33[40m%s\\33[0m (%4s k)\" % (name, spaces, round(count/1000, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a01fc879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA        \u001b[40m██████████████████████████████████\u001b[0m (34.33 k)\n",
      "France     \u001b[40m████████\u001b[0m (8.31 k)\n",
      "UK         \u001b[40m███████\u001b[0m (7.49 k)\n",
      "India      \u001b[40m██████\u001b[0m (6.37 k)\n",
      "Italy      \u001b[40m█████\u001b[0m (5.06 k)\n",
      "Germany    \u001b[40m███\u001b[0m (3.72 k)\n",
      "Japan      \u001b[40m███\u001b[0m ( 3.7 k)\n",
      "Canada     \u001b[40m███\u001b[0m (3.62 k)\n",
      "Spain      \u001b[40m██\u001b[0m (2.73 k)\n",
      "Hong Kong  \u001b[40m█\u001b[0m (1.88 k)\n"
     ]
    }
   ],
   "source": [
    "homework2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7208a7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib\n",
    "import requests\n",
    "from re import split\n",
    "\n",
    "def read_words(url, skip_until):\n",
    "    stop_words = [\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"\n",
    "    ]\n",
    "    input_file = urllib.request.urlopen(url)\n",
    "    word_set = set()\n",
    "    skip = True\n",
    "    for line in input_file :\n",
    "        line = line.decode('utf-8').strip()  \n",
    "        if not skip :\n",
    "            if line.find(skip_until) >= 0:\n",
    "                break\n",
    "            parts = split(\"[^a-zA-Z]+\", line) # notice this unique split function from the re module\n",
    "            for word in parts :\n",
    "                if len(word) > 0 :\n",
    "                    word_set.add(word.lower())\n",
    "        elif line.find(skip_until) >= 0 : \n",
    "            skip = False\n",
    "    return word_set\n",
    "\n",
    "def homework3():\n",
    "    url = \"https://www.gutenberg.org/files/11/old/alice30.txt\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "\n",
    "    my_dictionary = dict()\n",
    "    chapters = []\n",
    "    titles = dict()\n",
    "    lines = response.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        row = lines[i].decode('utf-8').strip()\n",
    "        if \"CHAPTER\" in row:\n",
    "            chpt = row\n",
    "            title = lines[i+2].decode('utf-8').lstrip().replace(\"\\r\\n\", \"\")\n",
    "            chapters.append(chpt)\n",
    "            titles[chpt] = title\n",
    "            my_dictionary[chpt] = \"\"\n",
    "    chapters.reverse()\n",
    "    for chap in chapters:\n",
    "        my_dictionary[chap] = read_words(url, chap)\n",
    "    print(\"%-15s %-40s %-s\" % (\"CHAPTER\", \"CHAPTER TITLE\", \"UNIQUE WORD COUNT\"))\n",
    "    for chap in my_dictionary:\n",
    "        print(\"%-15s %-40s %-s\" % (chap, titles[chap], len(my_dictionary[chap])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6aceed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER         CHAPTER TITLE                            UNIQUE WORD COUNT\n",
      "CHAPTER I       Down the Rabbit-Hole                     605\n",
      "CHAPTER II      The Pool of Tears                        601\n",
      "CHAPTER III     A Caucus-Race and a Long Tale            2342\n",
      "CHAPTER IV      The Rabbit Sends in a Little Bill        2218\n",
      "CHAPTER V       Advice from a Caterpillar                601\n",
      "CHAPTER VI      Pig and Pepper                           664\n",
      "CHAPTER VII     A Mad Tea-Party                          586\n",
      "CHAPTER VIII    The Queen's Croquet-Ground               1582\n",
      "CHAPTER IX      The Mock Turtle's Story                  1372\n",
      "CHAPTER X       The Lobster Quadrille                    530\n",
      "CHAPTER XI      Who Stole the Tarts?                     522\n",
      "CHAPTER XII     Alice's Evidence                         633\n"
     ]
    }
   ],
   "source": [
    "homework3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06d0f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def extra_credit_a():\n",
    "    class Country:\n",
    "        def __init__(self, name, count):\n",
    "            self.name = name\n",
    "            self.count = count\n",
    "    file = open(\"IMDb_movies.csv\", encoding='utf8')\n",
    "    file = csv.reader(file)\n",
    "    countries_all = []\n",
    "    countries_once = []\n",
    "    countries_end = []\n",
    "    for row in file:\n",
    "        if len(row[7].split(\",\")) >= 2:\n",
    "            for country in row[7].split(\", \"):\n",
    "                countries_all.append(country)\n",
    "                if country not in countries_once:\n",
    "                    countries_once.append(country)\n",
    "        else:\n",
    "            countries_all.append(row[7])\n",
    "            if row[7] not in countries_once:\n",
    "                countries_once.append(row[7])\n",
    "    for country in countries_once:\n",
    "        amount = countries_all.count(country)\n",
    "        countries_end.append(Country(country, amount))\n",
    "    countries_end = sorted(countries_end, key=lambda x:int(x.count), reverse = True)\n",
    "    colors = [\"\\33[31m\", \"\\33[32m\", \"\\33[33m\", \"\\33[34m\", \"\\33[35m\",\n",
    "             \"\\33[36m\", \"\\33[90m\", \"\\33[91m\", \"\\33[92m\", \"\\33[93m\"]\n",
    "    for i in range(10):\n",
    "        name = countries_end[i].name\n",
    "        count = countries_end[i].count\n",
    "        number_bars = int(count/1000)\n",
    "        spaces = \"\\u2588\"*number_bars\n",
    "        print(f\"%-10s %s%s\\33[0m (%4s k)\" % (name, colors[i], spaces, round(count/1000, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ee9c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA        \u001b[31m██████████████████████████████████\u001b[0m (34.33 k)\n",
      "France     \u001b[32m████████\u001b[0m (8.31 k)\n",
      "UK         \u001b[33m███████\u001b[0m (7.49 k)\n",
      "India      \u001b[34m██████\u001b[0m (6.37 k)\n",
      "Italy      \u001b[35m█████\u001b[0m (5.06 k)\n",
      "Germany    \u001b[36m███\u001b[0m (3.72 k)\n",
      "Japan      \u001b[90m███\u001b[0m ( 3.7 k)\n",
      "Canada     \u001b[91m███\u001b[0m (3.62 k)\n",
      "Spain      \u001b[92m██\u001b[0m (2.73 k)\n",
      "Hong Kong  \u001b[93m█\u001b[0m (1.88 k)\n"
     ]
    }
   ],
   "source": [
    "extra_credit_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "209ab5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m \u001b[41mF\u001b[41mL\u001b[41mO\u001b[41mR\u001b[41mI\u001b[41mD\u001b[41mA\u001b[41m'\u001b[41mS\n",
      "\u001b[41m \u001b[41m \u001b[41m \u001b[41mS\u001b[41mT\u001b[41mE\u001b[41mM\u001b[41m \u001b[41m \u001b[41m \u001b[41m \n",
      "\u001b[41mU\u001b[41mN\u001b[41mI\u001b[41mV\u001b[41mE\u001b[41mR\u001b[41mS\u001b[41mI\u001b[41mT\u001b[41mY\n",
      "\u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m/\u001b[46m`\u001b[46m·\u001b[46m.\u001b[46m ̧\n",
      "\u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m/\u001b[46m ̧\u001b[46m.\u001b[46m.\u001b[46m.\u001b[46m ̧\u001b[46m`\u001b[46m:\u001b[46m·\n",
      "\u001b[46m \u001b[46m ̧\u001b[46m.\u001b[46m·\u001b[46m ́\u001b[46m \u001b[46m \u001b[46m ̧\u001b[46m \u001b[46m \u001b[46m \u001b[46m`\u001b[46m·\u001b[46m.\u001b[46m ̧\u001b[46m.\u001b[46m·\u001b[46m ́\u001b[46m)\n",
      "\u001b[46m:\u001b[46m \u001b[46m©\u001b[46m \u001b[46m)\u001b[46m:\u001b[46m ́\u001b[46m;\u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m ̧\u001b[46m \u001b[46m \u001b[46m{\n",
      "\u001b[46m \u001b[46m`\u001b[46m·\u001b[46m.\u001b[46m ̧\u001b[46m \u001b[46m`\u001b[46m·\u001b[46m \u001b[46m \u001b[46m ̧\u001b[46m.\u001b[46m·\u001b[46m ́\u001b[46m\\\u001b[46m`\u001b[46m·\u001b[46m ̧\u001b[46m)\n",
      "\u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m \u001b[46m`\u001b[46m\\\u001b[46m\\\u001b[46m ́\u001b[46m ́\u001b[46m\\\u001b[46m ̧\u001b[46m.\u001b[46m·\u001b[46m ́\n",
      "\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m\\\n",
      "\u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\n",
      "\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\n",
      "\u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\n",
      "\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\n",
      "\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\n",
      "\u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\n",
      "\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\n",
      "\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\u001b[102m\\\u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\u001b[102m \u001b[102m \u001b[102m\\\u001b[102m \u001b[102m \u001b[102m/\n",
      "\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m/\u001b[102m \u001b[102m \u001b[102m \u001b[102m \u001b[102m\\\u001b[102m/\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m.\u001b[45m-\u001b[45m-\u001b[45m.\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m.\u001b[45m-\u001b[45m-\u001b[45m.\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m:\u001b[45m \u001b[45m(\u001b[45m\\\u001b[45m \u001b[45m\"\u001b[45m.\u001b[45m \u001b[45m_\u001b[45m.\u001b[45m.\u001b[45m.\u001b[45m.\u001b[45m.\u001b[45m.\u001b[45m_\u001b[45m \u001b[45m.\u001b[45m\"\u001b[45m \u001b[45m/\u001b[45m)\u001b[45m \u001b[45m:\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m'\u001b[45m.\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m`\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m`\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m.\u001b[45m'\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m/\u001b[45m'\u001b[45m \u001b[45m \u001b[45m \u001b[45m_\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m_\u001b[45m \u001b[45m \u001b[45m \u001b[45m`\u001b[45m\\\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m/\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m0\u001b[45m}\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m{\u001b[45m0\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m\\\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m_\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m/\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m\\\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m_\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m_\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m/\u001b[45m'\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m`\u001b[45m\\\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m_\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m\\\u001b[45m \u001b[45m \u001b[45m \u001b[45m_\u001b[45m \u001b[45m.\u001b[45m \u001b[45m \u001b[45m.\u001b[45m=\u001b[45m=\u001b[45m.\u001b[45m \u001b[45m \u001b[45m.\u001b[45m \u001b[45m_\u001b[45m \u001b[45m \u001b[45m \u001b[45m/\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m'\u001b[45m.\u001b[45m_\u001b[45m \u001b[45m\\\u001b[45m.\u001b[45m'\u001b[45m \u001b[45m\\\u001b[45m_\u001b[45m_\u001b[45m/\u001b[45m \u001b[45m'\u001b[45m.\u001b[45m/\u001b[45m \u001b[45m_\u001b[45m.\u001b[45m'\n",
      "\u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m \u001b[45m/\u001b[45m \u001b[45m \u001b[45m`\u001b[45m`\u001b[45m'\u001b[45m.\u001b[45m_\u001b[45m-\u001b[45m'\u001b[45m'\u001b[45m-\u001b[45m_\u001b[45m.\u001b[45m'\u001b[45m`\u001b[45m`\u001b[45m \u001b[45m \u001b[45m\\\n"
     ]
    }
   ],
   "source": [
    "def extra_credit_b(data, replacements, color):\n",
    "    # iterating through the all characters to be replace\n",
    "    # and the replacing list\n",
    "    # then replacing if one contains the other\n",
    "    for character in data:\n",
    "        for i in range(len(character)):\n",
    "            for replace in replacements:\n",
    "                if character[i] == replace[0]:\n",
    "                    character[i] = replace[1]\n",
    "            print(color + character[i], end=\"\")\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "data =[\n",
    "['!','F','L','O','R','/','D','A','\\'','_'],\n",
    "['!','!','!','_','T','*','M','!','!','!','!'],\n",
    "['U','N','/','V','*','R','_','/','T','Y']\n",
    "]\n",
    "replacements = [('*', 'E'), ('/', 'I'), ('!', ' '), ('_', 'S')]\n",
    "\n",
    "extra_credit_b(data, replacements, \"\\33[41m\")\n",
    "\n",
    "art1 =[\n",
    "['|','|','|','|','|','|','/','!','·','#','_'],\n",
    "['|','|','|','|','|','/','_','#','#','#','_','!','U','·'],\n",
    "['|','_','#','·',' ́','|','|','_','|','|','|','!','·','#','_','#','·',' ́','A'],\n",
    "['U','|','©','|','A','U',' ́',';','|','|','|','|','|','|','_','|','|','{'],\n",
    "['|','!','·','#','_','|','!','·','|','|','_','#','·',' ́','\\\\','!','·','_','A'],\n",
    "['|','|','|','|','|','!','\\\\','\\\\',' ́',' ́','\\\\','_','#','·',' ́']\n",
    "]\n",
    "replacements = [('|', ' '), ('!', '`'), ('_', ' ̧'), ('#', '.'), ('A',')'), ('U', ':')]\n",
    "\n",
    "extra_credit_b(art1, replacements, \"\\33[46m\")\n",
    "\n",
    "art2 = [\n",
    "[':',':',':',':','.','_',':',':',':',':','.','_'],\n",
    "[':',':',':','.',':',':','_',':',':','.',':',':','_'],\n",
    "[':',':','.',':','.','_',':','_','.',':','.','_',':','_'],\n",
    "[':','.',':','.',':',':','_',':','_','.',':',':','_',':','_'],\n",
    "['.',':','.',':',':',':','.','_',':','_',':',':',':','_',':','_'],\n",
    "['_',':','_',':',':','.',':','.','_',':','_',':',':','.',':','.'],\n",
    "[':','_',':','_','.',':','.',':',':','_',':','_','.',':','.'],\n",
    "[':',':','_','.',':','.',':',':',':',':','_','.',':','.'],\n",
    "[':',':','.',':','.','_',':',':',':',':','.',':','.','_'],\n",
    "[':','.',':','.','_',':','_',':',':','.',':','.','_',':','_'],\n",
    "['.',':','.',':',':','_',':','_','.',':','.',':',':','_',':','_'],\n",
    "['_',':','_',':',':',':','_',':','_','.',':',':',':','.',':','.'],\n",
    "[':','_',':','_',':',':','.','_',':','_',':',':','.',':','.'],\n",
    "[':',':','_',':','_','.',':','.','_',':','_','.',':','.'],\n",
    "[':',':',':','_',':',':','.',':',':','_',':',':','.'],\n",
    "[':',':',':',':','_','.',':',':',':',':','_','.']\n",
    "]\n",
    "replacements = [('.', '/'), ('_','\\\\'), (':', ' ')]\n",
    "\n",
    "extra_credit_b(art2, replacements, \"\\33[102m\")\n",
    "\n",
    "art3 = [\n",
    "['T','T','T','T','!','-','-','!','T','T','T','T','T','T','T','T','T','T','T','T','T','T','!','-','-','!'],\n",
    "['T','T','T',':','T','(','\\\\','T','\"','!','T','|','!','!','!','!','!','!','|','T','!','\"','T','/',')','T',':'],\n",
    "['T','T','T','T','\\'','!','T','T','T','T','`','T','T','T','T','T','T','T','T','`','T','T','T','T','!','\\''],\n",
    "['T','T','T','T','T','/','\\'','T','T','T','|','T','T','T','T','T','T','T','T','|','T','T','T','`','\\\\'],\n",
    "['T','T','T','T','/','T','T','T','T','T','y','}','T','T','T','T','T','T','{','y','T','T','T','T','T','\\\\'],\n",
    "['T','T','T','|','T','T','T','T','T','T','T','/','T','T','T','T','T','T','\\\\','T','T','T','T','T','T','T','|'],\n",
    "['T','T','T','|','T','T','T','T','T','/','\\'','T','T','T','T','T','T','T','T','`','\\\\','T','T','T','T','T','|'],\n",
    "['T','T','T','T','\\\\','T','T','T','|','T','!','T','T','!','=','=','!','T','T','!','T','|','T','T','T','/'],\n",
    "['T','T','T','T','T','\\'','!','|','T','\\\\','!','\\'','T','\\\\','|','|','/','T','\\'','!','/','T','|','!','\\''],\n",
    "['T','T','T','T','T','/','T','T','`','`','\\'','!','|','-','\\'','\\'','-','|','!','\\'','`','`','T','T','\\\\'],\n",
    "]\n",
    "replacements = [('|', '_'), ('T', ' '), ('!', '.'), ('y', '0')]\n",
    "\n",
    "extra_credit_b(art3, replacements, \"\\33[45m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
